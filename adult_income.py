# -*- coding: utf-8 -*-
"""Adult_Income.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s2qHJEBj4HBqQ2wjlo1k7pCdgsXSvZY_
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('/content/drive/MyDrive/Outlook/adult.csv',header=None)
df

df.rename(columns={0:'Age',
                  1: 'Workclass',
                  2: 'Fnlwgt',
                  3: 'Education',
                  4: 'education_num',
                  5: 'marital_status',
                  6: 'occupation',
                  7: 'relationship',
                  8: 'race',
                  9: 'sex',
                  10: 'capital_gain',
                  11: 'capital_loss',
                  12: 'hours_per_week',
                  13: 'native_country',
                  14: 'income'},inplace=True)
df

df.info()

df.describe()

df.shape

df.isnull().sum()

sns.heatmap(df.corr(),annot=True)

sns.countplot(df['income'])

corr = df.corr()
corr = corr[corr>0.5]
plt.figure(figsize=(9,9))
sns.heatmap(corr,annot=True,cmap='coolwarm')
plt.show()

df.dtypes

df.dtypes[df.dtypes=='object']

df['Workclass'].value_counts()

df['marital_status'].value_counts()

df['occupation'].value_counts()

df['relationship'].value_counts()

df['race'].value_counts()

df['sex'].value_counts()

df['native_country'].value_counts()

df['income'].value_counts()

df['Education'].value_counts()

from sklearn.preprocessing import LabelEncoder

label = LabelEncoder()

df['income'] = label.fit_transform(df['income'])
df['native_country'] = label.fit_transform(df['native_country'])
df['race'] = label.fit_transform(df['race'])
df['sex'] = label.fit_transform(df['sex'])
df['relationship'] = label.fit_transform(df['relationship'])
df['occupation'] = label.fit_transform(df['occupation'])
df['Workclass'] = label.fit_transform(df['Workclass'])
df['marital_status'] = label.fit_transform(df['marital_status'])
df['Education'] = label.fit_transform(df['Education'])

df.dtypes

df.corr()

corr = df.corr()
plt.figure(figsize=(9,9))
sns.heatmap(corr,annot=True,cmap='coolwarm')
plt.show()

df.columns

df

dict_acc = {}

x = df.drop(['income', 'Fnlwgt', 'hours_per_week','relationship'],axis=1)
y = df['income']

x

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.8,test_size=0.2)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_squared_error, mean_absolute_error, r2_score, precision_score, f1_score

def eval_metrics(y_test,y_pred):
    mse = mean_squared_error(y_test,y_pred)
    mae = mean_absolute_error(y_test,y_pred)
    rmse = np.sqrt(mean_squared_error(y_test,y_pred))
    r2s = r2_score(y_test,y_pred)
    print("MSE",mse)
    print("MAE",mae)
    print("RMSE",rmse)
    print("R2_Score",r2s)

def mscore(model):
    print("Training Score",model.score(x_train,y_train))
    print("Testing Score",model.score(x_test,y_test))

def accuracy(y_test,y_pred):
  print("Accuracy Score: ",accuracy_score(y_test,y_pred))
  print("Precision Score: ",precision_score(y_test,y_pred))
  print("F1 Score: ",f1_score(y_test,y_pred))
  print("Confusion Matrix: ", confusion_matrix(y_test,y_pred))
  print("Classification Report: ", classification_report(y_test,y_pred))

"""**Logistic Regression**"""

m1 = LogisticRegression()
m1.fit(x_train,y_train)

ypred_m1 = m1.predict(x_test)
ypred_m1

accuracy(y_test,ypred_m1)

dict_acc['LogisticRegression'] = accuracy_score(y_test,ypred_m1)
accuracy_score(y_test,ypred_m1)

mscore(m1)

eval_metrics(y_test,ypred_m1)

"""**Decision Tree Classifier (Grid Search)**"""

# Grid Search checks for all the possible permutations given in the parameters
# Takes a lot of time as it checks all the permutation and combination for given parameters

params_df1 = {'criterion':['gini','entropy'],'max_depth':list(range(7,12)),'min_samples_split':[10,12,15,18,20]}
params_df1

m2 = DecisionTreeClassifier()

gs1 = GridSearchCV(estimator=m2,param_grid=params_df1,scoring='accuracy')
gs1.fit(x_train,y_train)

ypred_m2_1 = gs1.predict(x_test)
ypred_m2_1

accuracy(y_test,ypred_m2_1)

dict_acc['DecisionTree_GS'] = accuracy_score(y_test,ypred_m2_1)

mscore(gs1)

eval_metrics(y_test,ypred_m2_1)

"""**Decision Tree Classifier (Random Search)**"""

#Random Search checks for few random combinations and selects the best possible outcome
# Takes less time to compute as it takes only few random parameter

rs1 = RandomizedSearchCV(estimator=m2,param_distributions=params_df1,scoring='accuracy',cv=10)
rs1.fit(x_train,y_train)

ypred_m2_2 = gs1.predict(x_test)
ypred_m2_2

accuracy(y_test,ypred_m2_2)

dict_acc['DecisionTree_RS'] = accuracy_score(y_test,ypred_m2_2)

mscore(gs1)

eval_metrics(y_test,ypred_m2_2)

"""**Random Forest Classifier (Grid Search)**"""

m3 = RandomForestClassifier()

gs2 = GridSearchCV(estimator=m3,param_grid=params_df1,scoring='accuracy')
gs2.fit(x_train,y_train)

ypred_m3_1 = gs2.predict(x_test)
ypred_m3_1

accuracy(y_test,ypred_m3_1)

dict_acc['RandomForest_GS'] = accuracy_score(y_test,ypred_m3_1)

mscore(gs2)

eval_metrics(y_test,ypred_m3_1)

"""**Random Forest Classifier (Randomized Search)**"""

rs2 = RandomizedSearchCV(estimator=m3,param_distributions=params_df1,scoring='accuracy',cv=10)
rs2.fit(x_train,y_train)

ypred_m3_2 = rs2.predict(x_test)
ypred_m3_2

accuracy(y_test,ypred_m3_2)

dict_acc['RandomForest_RS'] = accuracy_score(y_test,ypred_m3_2)

mscore(rs2)

eval_metrics(y_test,ypred_m3_2)

"""**KNeighborsClassifier (Grid Search)**"""

m4 = KNeighborsClassifier()

params_knn = {"n_neighbors":list(range(5,29))}
params_knn

gs3 = GridSearchCV(estimator= m4, param_grid=params_knn, scoring="accuracy")
gs3.fit(x_train,y_train)

ypred_m4_1 = gs3.predict(x_test)
ypred_m4_1

accuracy(y_test,ypred_m4_1)

dict_acc['KNN_GS'] = accuracy_score(y_test,ypred_m4_1)

mscore(gs3)

eval_metrics(y_test,ypred_m4_1)

"""**K Neighbors Classifier (Randomized Search)**"""

rs3 = RandomizedSearchCV(estimator= m4, param_distributions=params_knn, scoring="accuracy", cv=10)
rs3.fit(x_train,y_train)

ypred_m4_2 = rs3.predict(x_test)
ypred_m4_2

accuracy(y_test,ypred_m4_2)

dict_acc['KNN_RS'] = accuracy_score(y_test,ypred_m4_2)

mscore(rs3)

eval_metrics(y_test,ypred_m4_2)

"""**SVC**"""

m5 = SVC()

m5.fit(x_train,y_train)

ypred_m5 = m5.predict(x_test)
ypred_m5

accuracy(y_test,ypred_m5)

dict_acc['SVC'] = accuracy_score(y_test,ypred_m5)

mscore(m5)

eval_metrics(y_test,ypred_m5)

dict_acc

max=0
print(dict_acc.keys())
for i in dict_acc.keys():
  if dict_acc[i]>max:
    max = dict_acc[i]
    model = i
print(model,max)

print("Percentage of misclassification for each model is: \n")
for i in dict_acc:
  print(i,end=" ")
  print((1-dict_acc[i])*100)

print("Model with highest accuracy is",model,"and its accuracy is",max*100)

